<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="simple life"><title>Python网络爬虫1 - 爬取网易LOFTER图片 | LITREILY</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.png"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Python网络爬虫1 - 爬取网易LOFTER图片</h1><a id="logo" href="/.">LITREILY</a><p class="description">Stay Hungry, Stay Foolish</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="https://litreily.gitbooks.io/notes/"><i class="fa fa-book"> Notes</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/history/"><i class="fa fa-history"> History</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Python网络爬虫1 - 爬取网易LOFTER图片</h1><div class="post-meta">Mar 17, 2018<span> | </span><span class="category"><a href="/categories/Python/">Python</a></span></div><a class="disqus-comment-count" href="/2018/03/17/lofter/#vcomment"><span class="valine-comment-count" data-xid="/2018/03/17/lofter/"></span><span> Comment</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#分析LOFTER站点"><span class="toc-number">1.</span> <span class="toc-text">分析LOFTER站点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#主页信息"><span class="toc-number">1.1.</span> <span class="toc-text">主页信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分页信息"><span class="toc-number">1.2.</span> <span class="toc-text">分页信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#归档页信息"><span class="toc-number">1.3.</span> <span class="toc-text">归档页信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#博客页信息"><span class="toc-number">1.4.</span> <span class="toc-text">博客页信息</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#确定爬取方案"><span class="toc-number">2.</span> <span class="toc-text">确定爬取方案</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代码实现"><span class="toc-number">3.</span> <span class="toc-text">代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#依赖库"><span class="toc-number">3.1.</span> <span class="toc-text">依赖库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#获取用户ID"><span class="toc-number">3.2.</span> <span class="toc-text">获取用户ID</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#生成POST请求数据"><span class="toc-number">3.3.</span> <span class="toc-text">生成POST请求数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#发送POST请求包"><span class="toc-number">3.4.</span> <span class="toc-text">发送POST请求包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#解析POST响应包"><span class="toc-number">3.5.</span> <span class="toc-text">解析POST响应包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#下载图片"><span class="toc-number">3.6.</span> <span class="toc-text">下载图片</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#主循环"><span class="toc-number">3.7.</span> <span class="toc-text">主循环</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#完整代码"><span class="toc-number">3.8.</span> <span class="toc-text">完整代码</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#爬取测试"><span class="toc-number">4.</span> <span class="toc-text">爬取测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#说在最后"><span class="toc-number">5.</span> <span class="toc-text">说在最后</span></a></li></ol></div></div><div class="post-content"><p><code>LOFTER</code>是网易出品的优质轻博客，灵感源于国外的<code>tumblr</code>，但比之更加文艺，更加本地化。本人非常喜欢<code>LOFTER</code>的UI设计，以及其中的优质用户和内容，似乎网易并不擅长推广，所以受众并不广泛。这都是题外话，本文主要记录作者近期学习<code>python3</code>并用之爬取<code>LOFTER</code>用户图片的过程和成果，与大家交流分享。</p>
<blockquote>
<p>本文将以本人<a href="http://litreily.lofter.com" target="_blank" rel="noopener">litreily</a>博客为例说明整个爬取过程</p>
</blockquote>
<h2 id="分析LOFTER站点"><a href="#分析LOFTER站点" class="headerlink" title="分析LOFTER站点"></a>分析LOFTER站点</h2><p>在爬取站点之前，首先需要分析站点的关键信息有哪些，如果给自己提问，可能会有以下问题：</p>
<ol>
<li>用户的主页网址格式是？</li>
<li>用户博客链接的格式是？</li>
<li>每篇博客内的图片链接的格式是？</li>
<li>不同用户的主页模板不同，是否可以按同样方法抓取博客信息？</li>
<li>用户的博客数量巨大，主页以什么方式分页？</li>
<li>有没有归档页面方便爬取（大多数网站都有归档页面）？</li>
</ol>
<p>当然，这些问题不是一下子就能想出来，可以在探索网页内容的过程逐步展开，并思考下一步该考虑的问题，下面针对各个问题对主页进行探索分析。</p>
<h3 id="主页信息"><a href="#主页信息" class="headerlink" title="主页信息"></a>主页信息</h3><blockquote>
<p>主页: http://[username].lofter.com</p>
</blockquote>
<p><img src="/assets/spider/lofter/litreily.png" alt="litreily"></p>
<p>从主页可以看到<a href="http://litreily.lofter.com/view" target="_blank" rel="noopener">归档</a>的链接，暂时不管。不同的用户，其主页所用模板不尽一致，<code>LOFTER</code>为提供了大量精美的主页模板，以满足不同用户的需求：</p>
<p><img src="/assets/spider/lofter/lofterTemplet.png" alt="lofter templet"></p>
<p>然而，正是因为所用模板不同，其网页内容格式也不同，这个从不同模板中图片的位置，大小，图片信息等就可以看出来。相同的资源，不同的展示方式，就好像同样一件艺术品，既可以摆放在玻璃框中，也可以悬挂在高空。</p>
<p>当然这不是本文重点，这里只是为了说明不同用户的主页信息展示不一样，会给爬虫爬取带来一定影响。</p>
<h3 id="分页信息"><a href="#分页信息" class="headerlink" title="分页信息"></a>分页信息</h3><p>点击主页尾部的下一页，可以跳转至下一页，除首页和末页外，都会有上一页和下一页的链接，这里就给了我们一个提示，我们可以先抓取首页信息，然后从中抓取到<strong>下一页</strong>的链接，然后不断获取<strong>下一页</strong>的博客信息。</p>
<p><img src="/assets/spider/lofter/pages.png" alt="pages"></p>
<p>或者更简单点，看网址栏中的网址格式:</p>
<blockquote>
<p>分页： <code>http://[username].lofter.com/?page=[pageNumber]&amp;t=[timeStamp]</code></p>
</blockquote>
<p>直接使用<code>for</code>循环修改<code>page</code>值，逐页爬取博客信息。这貌似是个不错的想法，好，假设这样可行，那我们来分析每一页的信息。</p>
<p><img src="/assets/spider/lofter/postLink.png" alt="post link"></p>
<p>如上图所示，首先找到博文永久链接<code>http://litreily.lofter.com/post/44fbca_1265bb3e</code></p>
<p>针对含有图片的某一篇博文，<strong>litreily</strong>所用模板中会出现两次博文链接（见图中红框标注的两处），倘若我们使用正则表达式:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.findall(<span class="string">r'"http://.*lofter.com/post/[\w_]*"'</span>, html)</span><br></pre></td></tr></table></figure>
<p>将对每篇博文匹配出两个一样的链接，这可不是我们想要的，那咋整，匹配完再把重复的删了？不至于这么麻烦，细看两处链接前后信息，可以看到两处链接的<code>class</code>属性不一致，好办了，咱改改正则：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.findall(<span class="string">r'&lt;a class="img" href="(http://.*lofter.com/post/[\w_]*)"&gt;'</span>, html)</span><br></pre></td></tr></table></figure>
<p>好像可以了，这不就可以按页抓取博客链接，然后接着分析每篇博文信息不就好了么。我原本就想这么干，可是当我查看了不同用户的排版以及相应的链接信息后，整个人都不好了，一千个用户就是一千个哈姆雷特啊。如果你发现有统一解析所有用户模板信息的方法，那肯定是你看的模板不够多。</p>
<p>所以呢，这条路是走不通了，至少我没再往这条路上走。打道回府，只不过重头再来，路漫漫其修远兮，吾将上下而求索。</p>
<p>靠，说了半天，原来走不通，那你说个毛线！！！淡定淡定，都是文明人，后面的风景很远，额不是，，，是很美，请耐心等待…</p>
<h3 id="归档页信息"><a href="#归档页信息" class="headerlink" title="归档页信息"></a>归档页信息</h3><blockquote>
<p>归档页：<code>http://[username].lofter.com/view</code></p>
</blockquote>
<p>好了，还记得前面说的<strong>归档</strong>吧，归档可是个好东西，它把所有博文都按日期归档，最主要的是，所有用户的归档页面都是同一个模板，不管大V小v还是普通老百姓，真的是一视同仁。剩下的问题就是<strong>如何从归档页抓取每篇博客的真实路径</strong>。</p>
<p><img src="/assets/spider/lofter/archive.png" alt="archive"></p>
<p>先来看看归档页面的结构吧，博客按月份归档，每篇博客仅显示首张图片缩略图或纯文本。然后<code>F12</code>打开调试工具，如下图所示，每个月份对应一个<code>&lt;div class=&quot;m-filecnt m-filecnt-1&quot;&gt;</code>这样的节点，每个月份节点包含了本月所有博客的入口信息，一篇博客对应一个<code>id</code>号，以及一个博客的<strong>相对路径</strong>。<code>id</code>神马的不用关心，重点就是这个<strong>相对路径</strong>，有了它不就有了博客的绝对路径了么。</p>
<ul>
<li>相对路径：”/post/44fbca_1265bb3e”</li>
<li>绝对路径：”http://[username].lofter.com/post/44fbca_1265bb3e”</li>
</ul>
<p><img src="/assets/spider/lofter/archive_html.png" alt="archive structure"></p>
<p>这样看来，那岂不是只要抓取这一个归档页面就可以抓到所有的博客路径了呢？呵呵，真的这么容易吗？显然不大可能，当我们下拉页面时，归档信息将动态加载刷新，没错，是动态的！！！意料之中的猝不及防</p>
<p>接着我在Chrome浏览器中<code>Ctrl+U</code>看了看网页的源码（太长这就不放图了），果然不出所料，动态数据在源码中是木有的，只有一个脚本在那静静的躺着，躺着，躺着。。。难道就要放弃了吗，当然不！<strong>只要是网络通信，就必然有请求包和响应包</strong></p>
<p>那现在的问题就是，动态网页的数据是如果获取到的？动态数据的<strong>真实请求</strong>是什么？抓包看看呗，打开浏览器调试工具中的<code>Network</code>，刷新归档页，看看页面加载过程，找到真实请求，这个很好找，这类请求的后缀一般不会是png,jpg,gif,js,css等，而且多半是<strong>POST</strong>包，并且会出现在一堆图片请求的前面。</p>
<p><img src="/assets/spider/lofter/post.png" alt="post"></p>
<p>好了，找到了，就是上面这货。现在归档数据请求的链接有了，确实是<strong>POST</strong>包，同样，请求包的头部信息<code>headers</code>和请求参数<code>request payload</code>也有了。</p>
<p><img src="/assets/spider/lofter/post_values.png" alt="request values"></p>
<p>现在的关键问题是，这些请求包中的参数都是干嘛的？经我多方尝试、猜测与观察，总结如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">callCount=1       # 固定</span><br><span class="line">scriptSessionId=$&#123;scriptSessionId&#125;187   # 固定</span><br><span class="line">httpSessionId=    # 固定</span><br><span class="line">c0-scriptName=ArchiveBean       # 固定</span><br><span class="line">c0-methodName=getArchivePostByTime      # 固定</span><br><span class="line">c0-id=0           # 固定</span><br><span class="line">c0-param0=number:4520906        # 用户ID，可从用户主页源码获取</span><br><span class="line">c0-param1=number:1521342313224  # 时间戳，最最最关键参数！</span><br><span class="line">c0-param2=number:50       # 单次请求博客篇数，可以按需求修改</span><br><span class="line">c0-param3=boolean:false   # 固定</span><br><span class="line">batchId=822456            # 6位随机数，爬取时可以固定</span><br></pre></td></tr></table></figure>
<p>所以我们模拟请求包的时候就按这个来就可以了，至于时间戳怎么获取，请求包的<code>headers</code>如何确定，后面会有详述。</p>
<p>下面我们来看看请求后得到的响应包长啥样，look，就下面这个，看到没，<strong><code>permalink</code></strong>, 千呼万唤始出来啊，这不就是我们想要的博客固定路径了么。响应包并不是<code>html</code>文件，而是一组数据，我觉着归档页包含的那个脚本就是根据这个数据文件进而请求首张图片信息或文本信息的，当然这是我的猜测了，有兴趣的可以去看看那个脚本。</p>
<p><img src="/assets/spider/lofter/post_response.png" alt="post response"></p>
<p>有了这组数据，咱就可以获取每次请求得到的博客路径列表，进而逐一爬取博客内的图片链接了。</p>
<p>到此处为止，归档页的信息就分析完了，我们已经知道该发送怎样的请求包去获取归档数据，与此同时，我们也知道了从归档页如何获取每篇博客的真实路径。</p>
<p>下面就来看看当我们知道博客路径并抓取后，该如何获取每篇博客正文内的图片链接。</p>
<h3 id="博客页信息"><a href="#博客页信息" class="headerlink" title="博客页信息"></a>博客页信息</h3><blockquote>
<p>博客： <code>http://[username].lofter.com/post/******_********</code></p>
</blockquote>
<p>以上面获取的博客 <a href="http://litreily.lofter.com/post/33a459_1230cb50" target="_blank" rel="noopener">http://litreily.lofter.com/post/33a459_1230cb50</a> 为例，大部分博客内的图片都不止一张，这也是必须访问博客页本身的主要原因，好了照旧查看页面元素。</p>
<p><img src="/assets/spider/lofter/blog_pic.png" alt="blog pictures"></p>
<p>可以发现每篇博客内所有图片的大图链接都是上图框选中这样的，都有着同样的属性<code>bigimgsrc</code>，并且是博客页面唯一的。由于每篇博客源码内包含了该篇博客所有的图片链接，所以当我们获取了某篇博客的<code>html</code>文件后，便可以使用正则表达式获取所有图片链接。</p>
<p>至此，我们已经掌握了爬取<code>lofter</code>单用户博客图片所需的所有信息，是时候确定爬取方案了。</p>
<h2 id="确定爬取方案"><a href="#确定爬取方案" class="headerlink" title="确定爬取方案"></a>确定爬取方案</h2><p>首先，根据给定的<code>username</code>获取<code>uid</code>作为<code>POST</code>请求包数据中的一分子；然后，循环执行以下步骤直至全部爬取完成</p>
<ol>
<li>生成或更新归档页请求数据</li>
<li>模拟归档页面发送POST请求</li>
<li>解析响应数据并获取博客链接</li>
<li>逐一爬取博客内容</li>
<li>解析博客内容并获取图片链接</li>
<li>逐一下载图片至本地</li>
</ol>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>方案确定好了，那就撸起袖子加油干吧！</p>
<h3 id="依赖库"><a href="#依赖库" class="headerlink" title="依赖库"></a>依赖库</h3><ul>
<li>requests</li>
</ul>
<p>Only one! 没错，依赖的第三方库就这一个，怎么装咱这就不说了</p>
<h3 id="获取用户ID"><a href="#获取用户ID" class="headerlink" title="获取用户ID"></a>获取用户ID</h3><p>用户ID，确切的说是用户博客的唯一ID，是归档页请求报文中的参数之一，通过查看主页源码找到了相应的字符串，所以只要用<code>request.get</code>抓取首页然后匹配ID字符串就可以了，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_blogid</span><span class="params">(username)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = requests.get(<span class="string">'http://%s.lofter.com'</span> % username)</span><br><span class="line">        id_reg = <span class="string">r'src="http://www.lofter.com/control\?blogId=(.*)"'</span></span><br><span class="line">        blogid = re.search(id_reg, html.text).group(<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'The blogid of %s is: %s'</span> % (username, blogid))</span><br><span class="line">        <span class="keyword">return</span> blogid</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">'get blogid from http://%s.lofter.com failed'</span> % username)</span><br><span class="line">        print(<span class="string">'please check your username.'</span>)</span><br><span class="line">        exit(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="生成POST请求数据"><a href="#生成POST请求数据" class="headerlink" title="生成POST请求数据"></a>生成POST请求数据</h3><p>根据前面归档页的分析，我们知道POST请求中除了一些固定参数外，还有用户ID，时间戳<code>timestamp</code>以及单次请求的博客篇数<code>N</code>需要确定，而ID已经在前面已经获取到了；博客篇数可以自定义一个数，如40；最后就剩下时间戳了。</p>
<p>经过多次尝试发现，这个时间戳<code>timestamp</code>是所有参数中唯一一个需要在每次请求中不断更新的参数。那么它更新的依据是什么呢？每篇博客都对应着一个<code>timestamp</code>，而且是博客的发布时间，每次请求后得到的最后一篇博客的<code>timestamp</code>就可以作为下一次请求的<code>timestamp</code>。为什么呢，因为我多次实验发现，在给定一个<code>timestamp</code>并发送POST请求后，服务器会<strong>以请求参数中的时间戳为起点按时间顺序往前检索出指定篇数(如：40)的博客信息</strong></p>
<p>响应包的博客信息中包含了每篇博客的时间戳，所以每次获取响应包后，只要解析出响应包中最后一篇博客的时间戳，就可以作为下一次请求中的时间戳。</p>
<p>根据以上分析，可以写出获取时间戳的函数如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># time_pattern: re.compile('s%d\.time=(.*);s.*type' % (query_number-1))</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_timestamp</span><span class="params">(html, time_pattern)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> html:</span><br><span class="line">        timestamp = round(time.time() * <span class="number">1000</span>)  <span class="comment"># first timestamp(ms)</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        timestamp = time_pattern.search(html).group(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> str(timestamp)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意，首次请求的时间戳可以直接使用当前系统时间(ms)</p>
</blockquote>
<h3 id="发送POST请求包"><a href="#发送POST请求包" class="headerlink" title="发送POST请求包"></a>发送POST请求包</h3><p>POST请求包的<code>url</code>是固定的，<code>data</code>就是前面获取到的所有请求参数，<code>headers</code>如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36'</span>,</span><br><span class="line">        <span class="string">'Host'</span>: username + <span class="string">'.lofter.com'</span>,</span><br><span class="line">        <span class="string">'Referer'</span>: <span class="string">'http://%s.lofter.com/view'</span> % username,</span><br><span class="line">        <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate'</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>其中，<code>User-Agent</code>用于模拟浏览器请求，后面三个参数最好都加上，否则可能无法请求成功。POST请求其实就是一条语句<code>requests.post</code>，具体实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_html</span><span class="params">(url, data, headers)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = requests.post(url, data, headers = headers)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">"get %s failed\n%s"</span> % (url, str(e)))</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">return</span> html</span><br></pre></td></tr></table></figure>
<h3 id="解析POST响应包"><a href="#解析POST响应包" class="headerlink" title="解析POST响应包"></a>解析POST响应包</h3><p>在获取响应包的文本<code>html</code>后，便可从中获取本次请求得到的所有博客的相对路径，然后生成绝对路径，进而逐一抓取博客原文，从原文中抓取所有图链。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get urls of blogs: s3.permalink="44fbca_19a6b1b"</span></span><br><span class="line">new_blogs = blog_url_pattern.findall(html)</span><br><span class="line">num_new_blogs = len(new_blogs)</span><br><span class="line">num_blogs += num_new_blogs </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> num_new_blogs != <span class="number">0</span>:</span><br><span class="line">    print(<span class="string">'NewBlogs:%d\tTotalBolgs:%d'</span> % (num_new_blogs, num_blogs))</span><br><span class="line">    <span class="comment"># get imgurls from new_blogs</span></span><br><span class="line">    imgurls = []</span><br><span class="line">    <span class="keyword">for</span> blog <span class="keyword">in</span> new_blogs:</span><br><span class="line">        imgurls.extend(_get_imgurls(username, blog, headers))</span><br><span class="line">    num_imgs += len(imgurls)</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">以上代码便是获取POST的响应包`html`后的解析操作，其中`_get_imurls`是用于抓取博客原文并解析出所有图链的函数。</span><br><span class="line"></span><br><span class="line">``` python</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_imgurls</span><span class="params">(username, blog, headers)</span>:</span></span><br><span class="line">    blog_url = <span class="string">'http://%s.lofter.com/post/%s'</span> % (username, blog)</span><br><span class="line">    blog_html = requests.get(blog_url, headers = headers).text</span><br><span class="line">    imgurls = re.findall(<span class="string">r'bigimgsrc="(.*?)"'</span>, blog_html)</span><br><span class="line">    print(<span class="string">'Blog\t%s\twith %d\tpictures'</span> % (blog_url, len(imgurls)))</span><br><span class="line">    <span class="keyword">return</span> imgurls</span><br></pre></td></tr></table></figure>
<h3 id="下载图片"><a href="#下载图片" class="headerlink" title="下载图片"></a>下载图片</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_capture_images</span><span class="params">(imgurl, path)</span>:</span></span><br><span class="line">    headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36'</span>&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">3</span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            image_request = requests.get(imgurl, headers = headers, timeout = <span class="number">20</span>)</span><br><span class="line">            <span class="keyword">if</span> image_request.status_code == <span class="number">200</span>:</span><br><span class="line">                open(path, <span class="string">'wb'</span>).write(image_request.content)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">'\tGet %s failed\n\terror:%s'</span> % (imgurl, e))</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                imgurl = re.sub(<span class="string">'^http://img.*?\.'</span>,<span class="string">'http://img.'</span>,imgurl)</span><br><span class="line">                print(<span class="string">'\tRetry '</span> + imgurl)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">'\tRetry fail'</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>有了图链，最后的工作当然是下载图片了，上面这段代码便是用来下载图片的，<code>headers</code>是为了模拟浏览器访问。那为什么要尝试下载两次呢？因为我在抓取过程中，有时候会出现抓取失败的情况，并显示以下错误信息：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'Connection aborted.'</span><span class="string">,</span> <span class="string">RemoteDisconnected('Remote</span> <span class="string">end</span> <span class="string">closed</span> <span class="string">connection</span> <span class="string">without</span> <span class="string">response'</span></span><br></pre></td></tr></table></figure>
<p>所以在<code>Retry</code>前先将图链对应的<code>host</code>稍加修改,这样可以保证更高的成功率，但并不能完全避免。对于下载失败的情况，可能是：</p>
<ol>
<li>被反爬了（极大可能）</li>
<li>网络通信不畅（可能性低）</li>
<li>图链失效</li>
<li>服务器出毛病了</li>
</ol>
<p>有时候，同样一个图链，过一段时间去抓就好了，或者换个网络就好了。我猜测是被反爬，但证据不足，所以只能降低爬取频率，比如每发送接收一次POST请求便<code>sleep</code>10s左右，但还是会有失败的情况，如果大家有更好的意见，欢迎交流。目前情况，正常情况100%爬取完全没问题，异常情况90%以上吧。</p>
<h3 id="主循环"><a href="#主循环" class="headerlink" title="主循环"></a>主循环</h3><p>好了，其它零碎的代码就不多说了，爬虫主循环流程如下，其实就是以上步骤的整合：</p>
<ol>
<li>爬取归档页面指定篇数<code>query_number</code>的博文链接<code>new_blogs</code></li>
<li>逐个爬取博文<code>blog</code>数据，获取每篇<code>blog</code>的所有大图链接<code>imgurls</code></li>
<li>逐个爬取大图链接<code>imgurls</code>,下载图片至本地目录</li>
<li>判断是否已爬取完所有博文<ul>
<li>若已爬完，则显示爬取成果信息，并退出</li>
<li>若未爬完，则更新请求包中的时间戳<code>timestamp</code>，返回第1步继续爬取新的博文</li>
</ul>
</li>
</ol>
<h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># date: 2018.03.07</span></span><br><span class="line"><span class="string">"""Capture pictures from lofter with username."""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_path</span><span class="params">(username)</span>:</span></span><br><span class="line">    path = &#123;</span><br><span class="line">        <span class="string">'Windows'</span>: <span class="string">'D:/litreily/Pictures/python/lofter/'</span> + username,</span><br><span class="line">        <span class="string">'Linux'</span>: <span class="string">'/mnt/d/litreily/Pictures/python/lofter/'</span> + username</span><br><span class="line">    &#125;.get(platform.system())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(path):</span><br><span class="line">        os.makedirs(path)</span><br><span class="line">    <span class="keyword">return</span> path</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_html</span><span class="params">(url, data, headers)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = requests.post(url, data, headers = headers)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">"get %s failed\n%s"</span> % (url, str(e)))</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_blogid</span><span class="params">(username)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = requests.get(<span class="string">'http://%s.lofter.com'</span> % username)</span><br><span class="line">        id_reg = <span class="string">r'src="http://www.lofter.com/control\?blogId=(.*)"'</span></span><br><span class="line">        blogid = re.search(id_reg, html.text).group(<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'The blogid of %s is: %s'</span> % (username, blogid))</span><br><span class="line">        <span class="keyword">return</span> blogid</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">'get blogid from http://%s.lofter.com failed'</span> % username)</span><br><span class="line">        print(<span class="string">'please check your username.'</span>)</span><br><span class="line">        exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_timestamp</span><span class="params">(html, time_pattern)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> html:</span><br><span class="line">        timestamp = round(time.time() * <span class="number">1000</span>)  <span class="comment"># first timestamp(ms)</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        timestamp = time_pattern.search(html).group(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> str(timestamp)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_imgurls</span><span class="params">(username, blog, headers)</span>:</span></span><br><span class="line">    blog_url = <span class="string">'http://%s.lofter.com/post/%s'</span> % (username, blog)</span><br><span class="line">    blog_html = requests.get(blog_url, headers = headers).text</span><br><span class="line">    imgurls = re.findall(<span class="string">r'bigimgsrc="(.*?)"'</span>, blog_html)</span><br><span class="line">    print(<span class="string">'Blog\t%s\twith %d\tpictures'</span> % (blog_url, len(imgurls)))</span><br><span class="line">    <span class="keyword">return</span> imgurls</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_capture_images</span><span class="params">(imgurl, path)</span>:</span></span><br><span class="line">    headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36'</span>&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">3</span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            image_request = requests.get(imgurl, headers = headers, timeout = <span class="number">20</span>)</span><br><span class="line">            <span class="keyword">if</span> image_request.status_code == <span class="number">200</span>:</span><br><span class="line">                open(path, <span class="string">'wb'</span>).write(image_request.content)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">'\tGet %s failed\n\terror:%s'</span> % (imgurl, e))</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                imgurl = re.sub(<span class="string">'^http://img.*?\.'</span>,<span class="string">'http://img.'</span>,imgurl)</span><br><span class="line">                print(<span class="string">'\tRetry '</span> + imgurl)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">'\tRetry fail'</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_create_query_data</span><span class="params">(blogid, timestamp, query_number)</span>:</span></span><br><span class="line">    data = &#123;<span class="string">'callCount'</span>:<span class="string">'1'</span>,</span><br><span class="line">    <span class="string">'scriptSessionId'</span>:<span class="string">'$&#123;scriptSessionId&#125;187'</span>,</span><br><span class="line">    <span class="string">'httpSessionId'</span>:<span class="string">''</span>,</span><br><span class="line">    <span class="string">'c0-scriptName'</span>:<span class="string">'ArchiveBean'</span>,</span><br><span class="line">    <span class="string">'c0-methodName'</span>:<span class="string">'getArchivePostByTime'</span>,</span><br><span class="line">    <span class="string">'c0-id'</span>:<span class="string">'0'</span>,</span><br><span class="line">    <span class="string">'c0-param0'</span>:<span class="string">'number:'</span> + blogid,</span><br><span class="line">    <span class="string">'c0-param1'</span>:<span class="string">'number:'</span> + timestamp,</span><br><span class="line">    <span class="string">'c0-param2'</span>:<span class="string">'number:'</span> + query_number,</span><br><span class="line">    <span class="string">'c0-param3'</span>:<span class="string">'boolean:false'</span>,</span><br><span class="line">    <span class="string">'batchId'</span>:<span class="string">'123456'</span>&#125;</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># prepare paramters</span></span><br><span class="line">    username = <span class="string">'litreily'</span></span><br><span class="line">    blogid = _get_blogid(username)</span><br><span class="line">    query_number = <span class="number">40</span></span><br><span class="line">    time_pattern = re.compile(<span class="string">'s%d\.time=(.*);s.*type'</span> % (query_number<span class="number">-1</span>))</span><br><span class="line">    blog_url_pattern = re.compile(<span class="string">r's[\d]*\.permalink="([\w_]*)"'</span>) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># creat path to save imgs</span></span><br><span class="line">    path = _get_path(username)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># parameters of post packet</span></span><br><span class="line">    url = <span class="string">'http://%s.lofter.com/dwr/call/plaincall/ArchiveBean.getArchivePostByTime.dwr'</span> % username</span><br><span class="line">    data = _create_query_data(blogid, _get_timestamp(<span class="keyword">None</span>, time_pattern), str(query_number))</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36'</span>,</span><br><span class="line">        <span class="string">'Host'</span>: username + <span class="string">'.lofter.com'</span>,</span><br><span class="line">        <span class="string">'Referer'</span>: <span class="string">'http://%s.lofter.com/view'</span> % username,</span><br><span class="line">        <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate'</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    num_blogs = <span class="number">0</span></span><br><span class="line">    num_imgs = <span class="number">0</span></span><br><span class="line">    index_img = <span class="number">0</span></span><br><span class="line">    print(<span class="string">'------------------------------- start line ------------------------------'</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        html = _get_html(url, data, headers).text</span><br><span class="line">        <span class="comment"># get urls of blogs: s3.permalink="44fbca_19a6b1b"</span></span><br><span class="line">        new_blogs = blog_url_pattern.findall(html)</span><br><span class="line">        num_new_blogs = len(new_blogs)</span><br><span class="line">        num_blogs += num_new_blogs </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> num_new_blogs != <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'NewBlogs:%d\tTotalBolgs:%d'</span> % (num_new_blogs, num_blogs))</span><br><span class="line">            <span class="comment"># get imgurls from new_blogs</span></span><br><span class="line">            imgurls = []</span><br><span class="line">            <span class="keyword">for</span> blog <span class="keyword">in</span> new_blogs:</span><br><span class="line">                imgurls.extend(_get_imgurls(username, blog, headers))</span><br><span class="line">            num_imgs += len(imgurls)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># download imgs</span></span><br><span class="line">            <span class="keyword">for</span> imgurl <span class="keyword">in</span> imgurls:</span><br><span class="line">                index_img += <span class="number">1</span></span><br><span class="line">                paths = <span class="string">'%s/%d.%s'</span> % (path, index_img, re.search(<span class="string">r'(jpg|png|gif)'</span>, imgurl).group(<span class="number">0</span>))</span><br><span class="line">                print(<span class="string">'&#123;&#125;\t&#123;&#125;'</span>.format(index_img, paths))</span><br><span class="line">                _capture_images(imgurl, paths)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> num_new_blogs != query_number:</span><br><span class="line">            print(<span class="string">'------------------------------- stop line -------------------------------'</span>)</span><br><span class="line">            print(<span class="string">'capture complete!'</span>)</span><br><span class="line">            print(<span class="string">'captured blogs:%d images:%d'</span> % (num_blogs, num_imgs))</span><br><span class="line">            print(<span class="string">'download path:'</span> + path)</span><br><span class="line">            print(<span class="string">'-------------------------------------------------------------------------'</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        data[<span class="string">'c0-param1'</span>] = <span class="string">'number:'</span> + _get_timestamp(html, time_pattern)</span><br><span class="line">        print(<span class="string">'The next TimeStamp is : %s\n'</span> % data[<span class="string">'c0-param1'</span>].split(<span class="string">':'</span>)[<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># wait a few second</span></span><br><span class="line">        time.sleep(random.randint(<span class="number">5</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="爬取测试"><a href="#爬取测试" class="headerlink" title="爬取测试"></a>爬取测试</h2><p><img src="/assets/spider/lofter/lofter_spider.png" alt="lofter spider"></p>
<p><img src="/assets/spider/lofter/pictures.png" alt="pictures"></p>
<h2 id="说在最后"><a href="#说在最后" class="headerlink" title="说在最后"></a>说在最后</h2><ul>
<li>Github 源码：<a href="https://github.com/Litreily/capturer" target="_blank" rel="noopener">https://github.com/Litreily/capturer</a></li>
<li>欢迎交流探讨与STAR</li>
<li>请节制使用！</li>
</ul>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="http://www.litreily.top/2018/03/17/lofter/" data-id="cjreqvswh003wmvwt46m5oqs7" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABz0lEQVR42u3aQW4CMQwFUO5/aSqxQmozfMdJmEovK1RgeOnCir/zeMTr+Vqj1+/r999Hn3x/d/HCxcVtc5+Xa/Tzq56Zfx4XF/c8t1q8rgvW6MkJ/YMNFxf3Ztz8ZzqbxMXF/Y/c6w3kTREuLu79uf1GJf8X5KEJLi7ut7j9wLT/+mi+i4uL24g18wg1L2r5E/54Ji4u7hFuHn/0G57qQSfq1XBxcTdwk7iz2g6NnpBEHpPjVVxc3A3caqiRfzeJNgrv4uLiHuFeV4k8ssyPPnPlLCpquLi4i7jV0Wk+Jll1betD3cXFxd3AXXUNK485qhsuzHZwcXG3cfO2pzqCreYbUSHDxcU9wl01XJkcoFZ7NVxc3A3cueaneiSqbn5YyHBxcb/EzQ8i1WsWnV4GFxf3JLczDunEH/lVj6hXw8XFXcqd65Y66LlRyrD5wcXF3cBde6Eq31Je2obfwsXF3cadizX7pWryqgcuLu4Rbr7mRqedYlcOSnBxcZdy8+KVN0KdAe2HYxYuLu5B7twYdfGAJCmIuLi4t+T249G5AxMuLu49uXPz2+qANpoG4+LiHuHmzc+quxB5ISukvLi4uIu4c4Fplf7lfBcXFzfl/gDllUP6J+IrwQAAAABJRU5ErkJggg==">Share</a><div class="tags"><a href="/tags/tools/">tools</a><a href="/tags/spider/">spider</a><a href="/tags/lofter/">lofter</a></div><div class="post-nav"><a class="pre" href="/2018/04/10/sina/">Python网络爬虫2 - 爬取新浪微博用户图片</a><a class="next" href="/2018/02/22/ddos-attack/">两款实用的DDos攻击工具</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'1ecKy4yk4u1R7C4tScKbnyq9-gzGzoHsz',
  appKey:'uvA3xgqNW3q8TGR483lxXcpB',
  placeholder:'ヾﾉ≧∀≦)o Come on, say something...',
  avatar:'identicon',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/LabVIEW/">LabVIEW</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Matlab/">Matlab</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Media/">Media</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network/">Network</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web/">Web</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/嵌入式/">嵌入式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂物柜/">杂物柜</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/word/" style="font-size: 12px;">word</a> <a href="/tags/test/" style="font-size: 13.71px;">test</a> <a href="/tags/jekyll/" style="font-size: 15.43px;">jekyll</a> <a href="/tags/ruby/" style="font-size: 13.71px;">ruby</a> <a href="/tags/algorithm/" style="font-size: 20.57px;">algorithm</a> <a href="/tags/literature/" style="font-size: 12px;">literature</a> <a href="/tags/windows/" style="font-size: 13.71px;">windows</a> <a href="/tags/matlab/" style="font-size: 17.14px;">matlab</a> <a href="/tags/labview/" style="font-size: 22.29px;">labview</a> <a href="/tags/tdms/" style="font-size: 13.71px;">tdms</a> <a href="/tags/brackets/" style="font-size: 12px;">brackets</a> <a href="/tags/git/" style="font-size: 15.43px;">git</a> <a href="/tags/tools/" style="font-size: 17.14px;">tools</a> <a href="/tags/utorrent/" style="font-size: 12px;">utorrent</a> <a href="/tags/C-C/" style="font-size: 24px;">C/C++</a> <a href="/tags/ubuntu/" style="font-size: 22.29px;">ubuntu</a> <a href="/tags/linux/" style="font-size: 18.86px;">linux</a> <a href="/tags/atom/" style="font-size: 13.71px;">atom</a> <a href="/tags/music/" style="font-size: 13.71px;">music</a> <a href="/tags/signal/" style="font-size: 13.71px;">signal</a> <a href="/tags/VS/" style="font-size: 13.71px;">VS</a> <a href="/tags/stm32/" style="font-size: 13.71px;">stm32</a> <a href="/tags/hexo/" style="font-size: 13.71px;">hexo</a> <a href="/tags/RSS/" style="font-size: 12px;">RSS</a> <a href="/tags/Feed/" style="font-size: 12px;">Feed</a> <a href="/tags/FreeRTOS/" style="font-size: 12px;">FreeRTOS</a> <a href="/tags/log/" style="font-size: 12px;">log</a> <a href="/tags/office/" style="font-size: 12px;">office</a> <a href="/tags/makefile/" style="font-size: 13.71px;">makefile</a> <a href="/tags/wireshark/" style="font-size: 12px;">wireshark</a> <a href="/tags/telnet/" style="font-size: 12px;">telnet</a> <a href="/tags/smtp/" style="font-size: 12px;">smtp</a> <a href="/tags/tmux/" style="font-size: 13.71px;">tmux</a> <a href="/tags/shell/" style="font-size: 12px;">shell</a> <a href="/tags/mysql/" style="font-size: 12px;">mysql</a> <a href="/tags/centos/" style="font-size: 12px;">centos</a> <a href="/tags/ddos/" style="font-size: 12px;">ddos</a> <a href="/tags/hping3/" style="font-size: 12px;">hping3</a> <a href="/tags/spider/" style="font-size: 17.14px;">spider</a> <a href="/tags/sina/" style="font-size: 12px;">sina</a> <a href="/tags/lofter/" style="font-size: 12px;">lofter</a> <a href="/tags/scrapy/" style="font-size: 12px;">scrapy</a> <a href="/tags/pug/" style="font-size: 12px;">pug</a> <a href="/tags/queue/" style="font-size: 12px;">queue</a> <a href="/tags/xlwt/" style="font-size: 12px;">xlwt</a> <a href="/tags/sort/" style="font-size: 12px;">sort</a> <a href="/tags/visualization/" style="font-size: 13.71px;">visualization</a> <a href="/tags/ssh/" style="font-size: 12px;">ssh</a> <a href="/tags/proxy/" style="font-size: 12px;">proxy</a> <a href="/tags/vps/" style="font-size: 12px;">vps</a> <a href="/tags/stdio/" style="font-size: 12px;">stdio</a> <a href="/tags/cache/" style="font-size: 12px;">cache</a> <a href="/tags/buffer/" style="font-size: 12px;">buffer</a> <a href="/tags/pypcap/" style="font-size: 12px;">pypcap</a> <a href="/tags/dpkt/" style="font-size: 12px;">dpkt</a> <a href="/tags/MongoDB/" style="font-size: 12px;">MongoDB</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/22/highcharts/">Python之MongoDB数据分析及其Highcharts可视化</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/31/pypcap-install/">Python之pypcap库的安装及简单抓包工具的实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/25/autossh/">autossh反向代理实现内网穿透</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/25/io-cache/">Linux中的文件I/O缓冲</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/27/tee/">Linux指令 - tee的实现</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://www.smslit.top" title="smslit-水木十里" target="_blank">smslit-水木十里</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">LITREILY.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a>Theme with<a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> manupassant.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>